{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4120,"databundleVersionId":44256,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install torch-geometric and its dependencies\n!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.0.0+cpu.html","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:41:28.458826Z","iopub.execute_input":"2024-11-05T15:41:28.459700Z","iopub.status.idle":"2024-11-05T15:41:41.278326Z","shell.execute_reply.started":"2024-11-05T15:41:28.459657Z","shell.execute_reply":"2024-11-05T15:41:41.277255Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nRequirement already satisfied: torch-scatter in /opt/conda/lib/python3.10/site-packages (2.1.2+pt20cpu)\nRequirement already satisfied: torch-sparse in /opt/conda/lib/python3.10/site-packages (0.6.18+pt20cpu)\nRequirement already satisfied: torch-geometric in /opt/conda/lib/python3.10/site-packages (2.6.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.14.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.5)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.8.30)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:41:41.280846Z","iopub.execute_input":"2024-11-05T15:41:41.281918Z","iopub.status.idle":"2024-11-05T15:41:41.286893Z","shell.execute_reply.started":"2024-11-05T15:41:41.281860Z","shell.execute_reply":"2024-11-05T15:41:41.285938Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import torch \ndevice = torch.device(\"cpu\")  # Set device to CPU","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:41:41.288328Z","iopub.execute_input":"2024-11-05T15:41:41.288750Z","iopub.status.idle":"2024-11-05T15:41:41.297788Z","shell.execute_reply.started":"2024-11-05T15:41:41.288705Z","shell.execute_reply":"2024-11-05T15:41:41.296960Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Cleaning the dataset and data preprocessing","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch_geometric.nn import GCNConv\nimport polars as pl\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score, log_loss\nimport gc\n\n\n# Load the dataset using polars for better efficiency\ntrain_schema = {\n    'id': pl.UInt64,\n    'click': pl.Int8,\n    'hour': pl.String,\n    'C1': pl.Int16,\n    'banner_pos': pl.Int8,\n    'site_id': pl.Categorical,\n    'site_domain': pl.Categorical,\n    'site_category': pl.Categorical,\n    'app_id': pl.Categorical,\n    'app_domain': pl.Categorical,\n    'app_category': pl.Categorical,\n    'device_id': pl.Categorical,\n    'device_ip': pl.Categorical,\n    'device_model': pl.Categorical,\n    'device_type': pl.Int8,\n    'device_conn_type': pl.Int8,\n    'C14': pl.Int16,\n    'C15': pl.Int16,\n    'C16': pl.Int16,\n    'C17': pl.Int16,\n    'C18': pl.Int16,\n    'C19': pl.Int16,\n    'C20': pl.Int32,\n    'C21': pl.Int16\n}\n\ntest_schema = {\n    'id': pl.UInt64,\n    'hour': pl.String,\n    'C1': pl.Int16,\n    'banner_pos': pl.Int8,\n    'site_id': pl.Categorical,\n    'site_domain': pl.Categorical,\n    'site_category': pl.Categorical,\n    'app_id': pl.Categorical,\n    'app_domain': pl.Categorical,\n    'app_category': pl.Categorical,\n    'device_id': pl.Categorical,\n    'device_ip': pl.Categorical,\n    'device_model': pl.Categorical,\n    'device_type': pl.Int8,\n    'device_conn_type': pl.Int8,\n    'C14': pl.Int16,\n    'C15': pl.Int16,\n    'C16': pl.Int16,\n    'C17': pl.Int16,\n    'C18': pl.Int16,\n    'C19': pl.Int16,\n    'C20': pl.Int32,\n    'C21': pl.Int16\n}\n\n# Load train and test datasets\ntrain_df = pl.read_csv('/kaggle/input/avazu-ctr-prediction/train.gz', schema=train_schema)\ntest_df = pl.read_csv('/kaggle/input/avazu-ctr-prediction/test.gz', schema=test_schema)\n\n# Step 1: Sample a much smaller fraction (0.1%) of the data to reduce size\ntrain_df_sampled = train_df.sample(n=int(len(train_df) * 0.0001))  # Sample 0.01%\ntest_df_sampled = test_df.sample(n=int(len(test_df) * 0.0001))      # Sample 0.01%\n\n# Step 2: Feature Engineering - Extract 'hour_of_day' and 'day_of_month' from 'hour'\ndef extract_hour_features(df):\n    df = df.with_columns([\n        (pl.col('hour').str.slice(6, 2).cast(pl.Int8)).alias('hour_of_day'),   # Extract hour\n        (pl.col('hour').str.slice(4, 2).cast(pl.Int8)).alias('day_of_month')   # Extract day\n    ])\n    return df.drop('hour')\n\ntrain_df_sampled = extract_hour_features(train_df_sampled)\ntest_df_sampled = extract_hour_features(test_df_sampled)\n\n# Step 3: Remove unnecessary columns - Keep only a subset of important columns\nimportant_columns = [\n    'click', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n    'app_id', 'app_domain', 'app_category', 'device_id', 'device_model', \n    'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'hour_of_day', 'day_of_month'\n]\n\n# Select only these columns\ntrain_df_trimmed = train_df_sampled.select(important_columns)\ntest_df_trimmed = test_df_sampled.select([col for col in important_columns if col != 'click'])  # Exclude 'click' from test set\n\n# Step 4: Encode categorical features using LabelEncoder\ncategorical_columns = ['site_id', 'site_domain', 'site_category', 'app_id', 'app_domain',\n                       'app_category', 'device_id', 'device_model']\n\ndef label_encode_columns(df, columns):\n    for col in columns:\n        le = LabelEncoder()\n        df = df.with_columns([(pl.Series(col, le.fit_transform(df[col].to_numpy()))).alias(col)])\n    return df\n\n# Apply label encoding to train and test sets\ntrain_df_encoded = label_encode_columns(train_df_trimmed, categorical_columns)\ntest_df_encoded = label_encode_columns(test_df_trimmed, categorical_columns)\n\n# Step 5: Separate features and labels for training\nX_train = train_df_encoded.drop(['click']).to_pandas().values\ny_train = train_df_encoded['click'].to_pandas().values\n\n# Prepare Test Data\nX_test = test_df_encoded.to_pandas().values","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:41:41.300330Z","iopub.execute_input":"2024-11-05T15:41:41.300688Z","iopub.status.idle":"2024-11-05T15:42:36.707848Z","shell.execute_reply.started":"2024-11-05T15:41:41.300654Z","shell.execute_reply":"2024-11-05T15:42:36.706850Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Split data into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:36.709211Z","iopub.execute_input":"2024-11-05T15:42:36.709669Z","iopub.status.idle":"2024-11-05T15:42:36.716812Z","shell.execute_reply.started":"2024-11-05T15:42:36.709610Z","shell.execute_reply":"2024-11-05T15:42:36.715728Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Graph construction","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\n\ndef create_sparse_graph(X, threshold=0.05):\n    num_nodes = X.shape[0]\n    \n    # Create an array of possible edges (i, j) where i < j\n    row_indices = np.repeat(np.arange(num_nodes), num_nodes - 1)\n    col_indices = np.concatenate([np.delete(np.arange(num_nodes), i) for i in range(num_nodes)])\n    \n    # Generate random values to determine if an edge is created\n    edge_probs = np.random.rand(len(row_indices))\n    \n    # Select edges where the random value is less than the threshold\n    valid_edges = edge_probs < threshold\n    \n    # Get the selected edges\n    edge_index = np.column_stack((row_indices[valid_edges], col_indices[valid_edges]))\n    \n    # Ensure valid edges\n    if edge_index.size == 0:  # If no edges were added\n        edge_index = np.array([[0, 1], [1, 0]])  # Default edge to avoid empty graph\n    \n    edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n    \n    # Convert feature matrix to tensor\n    X_tensor = torch.tensor(X, dtype=torch.float)\n    \n    return X_tensor, edge_index","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:36.718276Z","iopub.execute_input":"2024-11-05T15:42:36.718634Z","iopub.status.idle":"2024-11-05T15:42:36.734534Z","shell.execute_reply.started":"2024-11-05T15:42:36.718589Z","shell.execute_reply":"2024-11-05T15:42:36.733479Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"X_train_tensor, edge_index = create_sparse_graph(X_train, threshold=0.1)  # Increase the threshold to reduce edge density\nX_val_tensor, _ = create_sparse_graph(X_val, threshold=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:36.735830Z","iopub.execute_input":"2024-11-05T15:42:36.736210Z","iopub.status.idle":"2024-11-05T15:42:37.065721Z","shell.execute_reply.started":"2024-11-05T15:42:36.736173Z","shell.execute_reply":"2024-11-05T15:42:37.064612Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"GCN Model","metadata":{}},{"cell_type":"code","source":"class GCNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(GCNModel, self).__init__()\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, output_dim)\n        \n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = torch.relu(x)\n        x = self.conv2(x, edge_index)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:37.067087Z","iopub.execute_input":"2024-11-05T15:42:37.067425Z","iopub.status.idle":"2024-11-05T15:42:37.074207Z","shell.execute_reply.started":"2024-11-05T15:42:37.067388Z","shell.execute_reply":"2024-11-05T15:42:37.072967Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def train_gcn_model(X_train, y_train, X_val, y_val, edge_index, input_dim, hidden_dim, output_dim, epochs=100, lr=0.01, batch_size=32):\n    model = GCNModel(input_dim, hidden_dim, output_dim).to(device)\n    criterion = nn.BCEWithLogitsLoss()  # Adjust based on your task (e.g., binary classification)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    # Convert labels to tensor and move to the correct device\n    y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n    X_train = X_train.to(device)\n    edge_index = edge_index.to(device)\n\n    # Training loop\n    for epoch in range(epochs):\n        model.train()\n        optimizer.zero_grad()\n\n        # Forward pass\n        out = model(X_train, edge_index)\n        \n        # Compute loss\n        loss = criterion(out.view(-1), y_train_tensor)\n        loss.backward()\n        optimizer.step()\n        \n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:37.075605Z","iopub.execute_input":"2024-11-05T15:42:37.075973Z","iopub.status.idle":"2024-11-05T15:42:37.087275Z","shell.execute_reply.started":"2024-11-05T15:42:37.075934Z","shell.execute_reply":"2024-11-05T15:42:37.086368Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(f\"X_train_tensor shape: {X_train_tensor.shape}, dtype: {X_train_tensor.dtype}\")\nprint(f\"X_val_tensor shape: {X_val_tensor.shape}, dtype: {X_val_tensor.dtype}\")\nprint(f\"edge_index shape: {edge_index.shape}, dtype: {edge_index.dtype}\")\nprint(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\nprint(f\"Unique labels in y_train: {np.unique(y_train)}\")  # Check if labels are 0 or 1","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:37.090556Z","iopub.execute_input":"2024-11-05T15:42:37.091324Z","iopub.status.idle":"2024-11-05T15:42:37.103658Z","shell.execute_reply.started":"2024-11-05T15:42:37.091284Z","shell.execute_reply":"2024-11-05T15:42:37.102467Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"X_train_tensor shape: torch.Size([3233, 17]), dtype: torch.float32\nX_val_tensor shape: torch.Size([809, 17]), dtype: torch.float32\nedge_index shape: torch.Size([2, 1046157]), dtype: torch.int64\ny_train shape: (3233,), dtype: int8\nUnique labels in y_train: [0 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for NaN or invalid values in y_train\nprint(f\"y_train contains NaN: {np.isnan(y_train).any()}\")\nprint(f\"y_train contains values outside [0, 1]: {(y_train < 0).any() or (y_train > 1).any()}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:37.107470Z","iopub.execute_input":"2024-11-05T15:42:37.108135Z","iopub.status.idle":"2024-11-05T15:42:37.114511Z","shell.execute_reply.started":"2024-11-05T15:42:37.108084Z","shell.execute_reply":"2024-11-05T15:42:37.113400Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"y_train contains NaN: False\ny_train contains values outside [0, 1]: False\n","output_type":"stream"}]},{"cell_type":"code","source":"# Try converting to tensor without sending to device first\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n\n# Print tensor stats before sending to GPU\nprint(f\"y_train_tensor stats - Min: {y_train_tensor.min()}, Max: {y_train_tensor.max()}\")\n\n# Now send to device\ny_train_tensor = y_train_tensor.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:37.115835Z","iopub.execute_input":"2024-11-05T15:42:37.116228Z","iopub.status.idle":"2024-11-05T15:42:37.125145Z","shell.execute_reply.started":"2024-11-05T15:42:37.116184Z","shell.execute_reply":"2024-11-05T15:42:37.124144Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"y_train_tensor stats - Min: 0.0, Max: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert y_train to torch.float32 for BCEWithLogitsLoss\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n\n# Move tensors to device\nX_train_tensor = X_train_tensor.to(device)\nX_val_tensor = X_val_tensor.to(device)\nedge_index = edge_index.to(device)\n\n# Check after moving to device\n# Assuming the tensors are already defined and moved to CPU\nprint(f\"X_train_tensor is on device: {X_train_tensor.device}\")\nprint(f\"X_val_tensor is on device: {X_val_tensor.device}\")\nprint(f\"edge_index is on device: {edge_index.device}\")\nprint(f\"y_train_tensor is on device: {y_train_tensor.device}\")\n\n# Define input/output dimensions\ninput_dim = X_train_tensor.shape[1]\nhidden_dim = 64  # You can adjust this\noutput_dim = 1   # Adjust based on your task\n\n# Train the model\nmodel = train_gcn_model(X_train_tensor, y_train_tensor, X_val_tensor, y_val, edge_index, input_dim, hidden_dim, output_dim)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:42:37.126657Z","iopub.execute_input":"2024-11-05T15:42:37.127090Z","iopub.status.idle":"2024-11-05T15:43:44.865741Z","shell.execute_reply.started":"2024-11-05T15:42:37.127049Z","shell.execute_reply":"2024-11-05T15:43:44.864507Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"X_train_tensor is on device: cpu\nX_val_tensor is on device: cpu\nedge_index is on device: cpu\ny_train_tensor is on device: cpu\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/1743774894.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/100], Loss: 509.5795\nEpoch [20/100], Loss: 319.3154\nEpoch [30/100], Loss: 22.3242\nEpoch [40/100], Loss: 34.4552\nEpoch [50/100], Loss: 182.1496\nEpoch [60/100], Loss: 94.7406\nEpoch [70/100], Loss: 63.6325\nEpoch [80/100], Loss: 42.6895\nEpoch [90/100], Loss: 198.0491\nEpoch [100/100], Loss: 28.4504\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"X_val_tensor on device: {X_val_tensor.device}\")\nprint(f\"edge_index on device: {edge_index.device}\")\nprint(f\"y_val on device: {torch.tensor(y_val, dtype=torch.float32).device}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:43:44.867396Z","iopub.execute_input":"2024-11-05T15:43:44.868521Z","iopub.status.idle":"2024-11-05T15:43:44.875070Z","shell.execute_reply.started":"2024-11-05T15:43:44.868474Z","shell.execute_reply":"2024-11-05T15:43:44.873882Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"X_val_tensor on device: cpu\nedge_index on device: cpu\ny_val on device: cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"GCN Implementation","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Define device as CPU\ndevice = torch.device(\"cpu\")\n\n# Reconstruct tensors on CPU to ensure a fresh start\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32)\nedge_index = torch.tensor(edge_index, dtype=torch.int64)\n\n# Ensure label tensors are in the correct format for BCEWithLogitsLoss\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n\n# Check unique indices in edge_index\nprint(f\"Unique indices in edge_index: {torch.unique(edge_index)}\")\nprint(f\"Maximum index in edge_index: {edge_index.max()}\")\nprint(f\"Number of nodes in X_val_tensor: {X_val_tensor.shape[0]}\")\n\n# Filter out invalid edges\nmax_index = X_val_tensor.shape[0] - 1\nvalid_edges = edge_index[:, (edge_index[0] <= max_index) & (edge_index[1] <= max_index)]\n\n# Print filtered edge index information\nprint(f\"Filtered edge_index: shape = {valid_edges.shape}, unique indices = {torch.unique(valid_edges)}\")\n\n# Evaluation on CPU\nmodel.eval()\nwith torch.no_grad():\n    val_out = model(X_val_tensor, valid_edges)  # Use filtered edge index\n    val_out = torch.sigmoid(val_out)\n\n    # Convert predictions and labels to numpy arrays for metric calculation\n    val_out_np = val_out.numpy()\n    y_val_np = y_val_tensor.numpy()\n\n    # Apply binary threshold for classification\n    y_pred = (val_out_np >= 0.5).astype(int)\n    accuracy = (y_pred.flatten() == y_val_np).mean()\n    print(f\"Validation Accuracy on CPU: {accuracy:.4f}\")\n\n    # Additional metrics using sklearn\n    precision = precision_score(y_val_np, y_pred)\n    recall = recall_score(y_val_np, y_pred)\n    f1 = f1_score(y_val_np, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:43:44.876330Z","iopub.execute_input":"2024-11-05T15:43:44.876703Z","iopub.status.idle":"2024-11-05T15:43:45.053855Z","shell.execute_reply.started":"2024-11-05T15:43:44.876663Z","shell.execute_reply":"2024-11-05T15:43:45.052597Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Unique indices in edge_index: tensor([   0,    1,    2,  ..., 3230, 3231, 3232])\nMaximum index in edge_index: 3232\nNumber of nodes in X_val_tensor: 809\nFiltered edge_index: shape = torch.Size([2, 65334]), unique indices = tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n        504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n        518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n        574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n        588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n        602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n        616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n        630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n        644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n        658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671,\n        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n        686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699,\n        700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713,\n        714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n        728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741,\n        742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755,\n        756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769,\n        770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783,\n        784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797,\n        798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808])\nValidation Accuracy on CPU: 0.8405\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/861299152.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  edge_index = torch.tensor(edge_index, dtype=torch.int64)\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Improving the Model:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch_geometric.nn import GCNConv\nfrom torch_geometric.utils import to_undirected\nfrom sklearn.metrics import roc_auc_score, log_loss, accuracy_score, precision_score, recall_score, f1_score\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch_geometric.utils import add_self_loops\n\n# Define the enhanced GCN model with multi-layer and specified embedding\nclass EnhancedGCNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.5):\n        super(EnhancedGCNModel, self).__init__()\n        self.embedding_layer = nn.Linear(input_dim, 8)  # Embedding layer\n        self.convs = nn.ModuleList()\n        self.bns = nn.ModuleList()\n        \n        # Define multiple GCN layers as per the paper\n        for i in range(num_layers):\n            in_dim = 8 if i == 0 else hidden_dim\n            self.convs.append(GCNConv(in_dim, hidden_dim))\n            self.bns.append(nn.BatchNorm1d(hidden_dim))\n        \n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, x, edge_index):\n        x = self.embedding_layer(x)\n        \n        for conv, bn in zip(self.convs, self.bns):\n            x = conv(x, edge_index)\n            x = bn(x)\n            x = self.activation(x)\n            x = self.dropout(x)\n        \n        x = self.fc(x)\n        return x\n\n# Training function with batch-wise edge filtering\ndef train_model(model, train_loader, edge_index, optimizer, criterion, num_epochs=100):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for batch_x, batch_y in train_loader:\n            batch_nodes = batch_x.shape[0]\n            \n            # Filter edge_index for the batch to only contain within-batch edges\n            mask = (edge_index[0] < batch_nodes) & (edge_index[1] < batch_nodes)\n            batch_edge_index = edge_index[:, mask]\n            \n            optimizer.zero_grad()\n            out = model(batch_x, batch_edge_index)\n            loss = criterion(out.view(-1), batch_y.float())\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n        # Print epoch loss every 10 epochs\n        if epoch % 10 == 0:\n            avg_loss = total_loss / len(train_loader)\n            print(f'Epoch [{epoch}/{num_epochs}], Loss: {avg_loss:.4f}')\n            \ndef evaluate_model(model, X_val_tensor, edge_index, y_val_tensor):\n    model.eval()\n    with torch.no_grad():\n        # Map nodes in X_val_tensor to the corresponding range in edge_index\n        unique_nodes = torch.arange(X_val_tensor.size(0), device=edge_index.device)\n        node_map = {n.item(): i for i, n in enumerate(unique_nodes)}\n\n        # Filter edge_index to only include edges within the validation set\n        mask = (edge_index[0] < X_val_tensor.size(0)) & (edge_index[1] < X_val_tensor.size(0))\n        filtered_edge_index = edge_index[:, mask]\n        \n        # Map the edges to the new subset of nodes\n        filtered_edge_index = torch.stack([\n            torch.tensor([node_map.get(n.item(), -1) for n in filtered_edge_index[0]]),\n            torch.tensor([node_map.get(n.item(), -1) for n in filtered_edge_index[1]])\n        ], dim=0)\n        \n        # Remove any edges with -1 (those outside the mapped range)\n        valid_edges = (filtered_edge_index != -1).all(dim=0)\n        filtered_edge_index = filtered_edge_index[:, valid_edges]\n        \n        # Forward pass with filtered edge_index\n        out = model(X_val_tensor, filtered_edge_index)\n        out_sigmoid = torch.sigmoid(out).view(-1).cpu().numpy()\n        y_true = y_val_tensor.cpu().numpy()\n\n        # Calculate evaluation metrics\n        auc = roc_auc_score(y_true, out_sigmoid)\n        logloss = log_loss(y_true, out_sigmoid)\n        accuracy = accuracy_score(y_true, (out_sigmoid >= 0.5).astype(int))\n       \n\n        print(f'Validation AUC: {auc:.4f}')\n        print(f'Validation Log Loss: {logloss:.4f}')\n        print(f'Validation Accuracy: {accuracy:.4f}')\n        \n        return auc, logloss, accuracy\n    # Prepare data for training and validation\n# Assume X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, edge_index are defined elsewhere\n# Update edge_index to undirected and with self-loops\nedge_index = to_undirected(edge_index)\nedge_index, _ = add_self_loops(edge_index)\n\n# Define parameters\ninput_dim = X_train_tensor.shape[1]\nhidden_dim = 64\noutput_dim = 1\nbatch_size = 1024\nlearning_rate = 0.01\nnum_epochs = 100\n\n# Instantiate model, optimizer, and loss function\nmodel = EnhancedGCNModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\ncriterion = nn.BCEWithLogitsLoss()\n\n# Set up DataLoader for batch training\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Train the model\ntrain_model(model, train_loader, edge_index, optimizer, criterion, num_epochs)\n\n# Evaluate the model on validation data\nevaluate_model(model, X_val_tensor, edge_index, y_val_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:43:45.055297Z","iopub.execute_input":"2024-11-05T15:43:45.055706Z","iopub.status.idle":"2024-11-05T15:45:40.842836Z","shell.execute_reply.started":"2024-11-05T15:43:45.055661Z","shell.execute_reply":"2024-11-05T15:45:40.841830Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch [0/100], Loss: 0.5632\nEpoch [10/100], Loss: 0.4671\nEpoch [20/100], Loss: 0.5016\nEpoch [30/100], Loss: 0.4808\nEpoch [40/100], Loss: 0.4800\nEpoch [50/100], Loss: 0.4616\nEpoch [60/100], Loss: 0.4619\nEpoch [70/100], Loss: 0.4655\nEpoch [80/100], Loss: 0.4669\nEpoch [90/100], Loss: 0.4685\nValidation AUC: 0.5193\nValidation Log Loss: 1.3986\nValidation Accuracy: 0.8405\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(0.5192772457820338, 1.3985619840181394, 0.8405438813349815)"},"metadata":{}}]},{"cell_type":"markdown","source":"GNN model implementation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch_geometric.nn import SAGEConv  # Change to other layers if needed\nfrom torch_geometric.utils import to_undirected, add_self_loops\nfrom sklearn.metrics import roc_auc_score, log_loss, accuracy_score\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Define the generic GNN model with multi-layer capability\nclass EnhancedGNNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.5):\n        super(EnhancedGNNModel, self).__init__()\n        self.embedding_layer = nn.Linear(input_dim, 8)  # Embedding layer\n        self.convs = nn.ModuleList()\n        self.bns = nn.ModuleList()\n        \n        # Define multiple GNN layers\n        for i in range(num_layers):\n            in_dim = 8 if i == 0 else hidden_dim\n            self.convs.append(SAGEConv(in_dim, hidden_dim))\n            self.bns.append(nn.BatchNorm1d(hidden_dim))\n        \n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, x, edge_index):\n        x = self.embedding_layer(x)\n        \n        for conv, bn in zip(self.convs, self.bns):\n            x = conv(x, edge_index)\n            x = bn(x)\n            x = self.activation(x)\n            x = self.dropout(x)\n        \n        x = self.fc(x)\n        return x\n\n# Training function with batch-wise edge filtering\ndef train_model(model, train_loader, edge_index, optimizer, criterion, num_epochs=100):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for batch_x, batch_y in train_loader:\n            batch_nodes = batch_x.shape[0]\n            \n            # Filter edge_index for the batch to only contain within-batch edges\n            mask = (edge_index[0] < batch_nodes) & (edge_index[1] < batch_nodes)\n            batch_edge_index = edge_index[:, mask]\n            \n            optimizer.zero_grad()\n            out = model(batch_x, batch_edge_index)\n            loss = criterion(out.view(-1), batch_y.float())\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n        # Print epoch loss every 10 epochs\n        if epoch % 10 == 0:\n            avg_loss = total_loss / len(train_loader)\n            print(f'Epoch [{epoch}/{num_epochs}], Loss: {avg_loss:.4f}')\n\ndef evaluate_model(model, X_val_tensor, edge_index, y_val_tensor):\n    model.eval()\n    with torch.no_grad():\n        # Map node indices in X_val_tensor to global indices\n        node_map = {node.item(): i for i, node in enumerate(torch.arange(X_val_tensor.shape[0]))}\n        \n        # Filter edge_index for the batch to include only nodes in X_val_tensor\n        mask = (edge_index[0] < X_val_tensor.shape[0]) & (edge_index[1] < X_val_tensor.shape[0])\n        filtered_edge_index = edge_index[:, mask]\n        \n        out = model(X_val_tensor, filtered_edge_index)\n        out_sigmoid = torch.sigmoid(out).view(-1).cpu().numpy()\n        y_true = y_val_tensor.cpu().numpy()\n\n        # Calculate only AUC, Log Loss, and Accuracy\n        auc = roc_auc_score(y_true, out_sigmoid)\n        logloss = log_loss(y_true, out_sigmoid)\n        accuracy = accuracy_score(y_true, (out_sigmoid >= 0.5).astype(int))\n        \n        print(f'Validation AUC: {auc:.4f}')\n        print(f'Validation Log Loss: {logloss:.4f}')\n        print(f'Validation Accuracy: {accuracy:.4f}')\n        \n        return auc, logloss, accuracy\n\n\n# Prepare data for training and validation\n# Assume X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, edge_index are defined elsewhere\n# Update edge_index to undirected and with self-loops\nedge_index = to_undirected(edge_index)\nedge_index, _ = add_self_loops(edge_index)\n\n# Define parameters\ninput_dim = X_train_tensor.shape[1]\nhidden_dim = 64\noutput_dim = 1\nbatch_size = 1024\nlearning_rate = 0.01\nnum_epochs = 100\n\n# Instantiate model, optimizer, and loss function\nmodel = EnhancedGNNModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\ncriterion = nn.BCEWithLogitsLoss()\n\n# Set up DataLoader for batch training\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Train the model\ntrain_model(model, train_loader, edge_index, optimizer, criterion, num_epochs)\n\n# Evaluate the model on validation data\nevaluate_model(model, X_val_tensor, edge_index, y_val_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T15:45:40.844546Z","iopub.execute_input":"2024-11-05T15:45:40.844887Z","iopub.status.idle":"2024-11-05T15:46:33.727240Z","shell.execute_reply.started":"2024-11-05T15:45:40.844852Z","shell.execute_reply":"2024-11-05T15:46:33.726209Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch [0/100], Loss: 0.5794\nEpoch [10/100], Loss: 0.4773\nEpoch [20/100], Loss: 0.4758\nEpoch [30/100], Loss: 0.4745\nEpoch [40/100], Loss: 0.4739\nEpoch [50/100], Loss: 0.4559\nEpoch [60/100], Loss: 0.4585\nEpoch [70/100], Loss: 0.4354\nEpoch [80/100], Loss: 0.4436\nEpoch [90/100], Loss: 0.4489\nValidation AUC: 0.5309\nValidation Log Loss: 0.4545\nValidation Accuracy: 0.8405\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(0.530859553123575, 0.4544685356991035, 0.8405438813349815)"},"metadata":{}}]}]}